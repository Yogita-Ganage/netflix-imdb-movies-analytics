{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "878240a1-b3dd-4269-aecd-5e6e071090bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Silver Layer – Transformation & Conformance (Assumptions & Design Notes)\n",
    "\n",
    "**Purpose:**  \n",
    "Transform raw Bronze data into clean, standardized, analytics-ready tables while applying all business rules defined in the task.\n",
    "\n",
    "## Key Assumptions\n",
    "### General Processing\n",
    "- All column names must be converted to **lowerCamelCase**.\n",
    "- Text cleanup includes trimming whitespace and converting empty strings to `NULL`.\n",
    "- Titles such as \"1. The Matrix\" are cleaned by removing leading numeric prefixes.\n",
    "- Titles that are NULL, empty, or \"[]\" are considered junk and removed.\n",
    "\n",
    "### Netflix Processing\n",
    "- Only records where `type == \"MOVIE\" are required for the analytical model.\n",
    "- If multiple Netflix movies have the same (title, releaseYear),  \n",
    "- the version with the highest imdbScore is retained.\n",
    "- Director assignment:\n",
    "  - Taken from 'netflix_credits_raw'.\n",
    "  - If multiple directors exist, the earliest person_id is selected.\n",
    "- Runtime, IMDB score, TMDB metrics, votes, and release year are cast to numeric types.\n",
    "\n",
    "### IMDB Processing\n",
    "- Only 'imdb_merged_movies_raw' is required for matching with Netflix movies.\n",
    "- Release year is derived from:\n",
    "  1. 'release_date' (parsed), else  \n",
    "  2. Fallback to raw 'year' column.\n",
    "- Runtime is normalized to integer minutes from formats like \"1h 42m\" / \"95m\".\n",
    "- 'imdbRating' and 'imdbVotes' are parsed as numeric fields.\n",
    "- If multiple entries exist for the same (titleNorm, releaseYear),  \n",
    "  the row with highest IMDB rating, then highest votes is selected.\n",
    "\n",
    "### Joining Netflix & IMDB\n",
    "- Join priority:\n",
    "  1. Primary: imdbId match  \n",
    "  2. Fallback: (titleNorm, releaseYear)\n",
    "- IMDB rating & votes priority:\n",
    "  - Use **IMDB dataset first**\n",
    "  - Fallback to Netflix 'imdbScore' and 'imdbVotes' when IMDB data is missing.\n",
    "- Only movies coming from Netflix should appear in the final model  \n",
    "  (Silver movies table is left-joined from Netflix → IMDB).\n",
    "\n",
    "## Output Silver Tables\n",
    "- silver.netflix_movies – cleaned Netflix dataset with one movie per title/year.\n",
    "- silver.imdb_movies – deduplicated IMDB dataset with standardized fields.\n",
    "- silver.movies – unified movie model containing:\n",
    "  - title, releaseYear, runtimeMinutes\n",
    "  - director, genres, productionCountries\n",
    "  - imdbRating (IMDB-first), imdbVotes (IMDB-first)\n",
    "  - tmdbPopularity, tmdbScore\n",
    "  - hasImdbMatch flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb46ab38-8ad1-407c-a2da-d3d377b27954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c52c34e-4095-4899-93d2-218a499510c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Catalog and Schema Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65dfa706-1cd0-458c-a8ef-fee02b3ee21d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG workspace;\n",
    "CREATE SCHEMA IF NOT EXISTS silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e68d5a1-a95f-4f5a-8a10-78b6fc578e34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e28d5a5-3ada-456b-9739-a3409270920d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34879bae-0a41-4940-9bda-7ebc36e8e2fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e05efb3-15ee-4144-97e6-e812517f584a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_string_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Trim whitespace and convert empty strings to NULL for all string columns.\n",
    "    \"\"\"\n",
    "    for col_name, col_type in df.dtypes:\n",
    "        if col_type == \"string\":\n",
    "            df = df.withColumn(\n",
    "                col_name,\n",
    "                F.when(F.trim(F.col(col_name)) == \"\", F.lit(None))\n",
    "                 .otherwise(F.trim(F.col(col_name)))\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "def to_camel_case(col_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert snake_case / spaces / UPPER to lowerCamelCase.\n",
    "    If the name already looks like camelCase or PascalCase, keep it\n",
    "    (just force first letter to lower-case).\n",
    "    \"\"\"\n",
    "    if col_name is None:\n",
    "        return col_name\n",
    "\n",
    "    raw = col_name.strip()\n",
    "    if raw == \"\":\n",
    "        return raw\n",
    "\n",
    "    # Already a single token (no _ / space) and not all upper → treat as camel/pascal\n",
    "    if \"_\" not in raw and \" \" not in raw and not raw.isupper():\n",
    "        return raw[0].lower() + raw[1:]\n",
    "\n",
    "    # Otherwise, snake/space → camel\n",
    "    parts = raw.replace(\" \", \"_\").split(\"_\")\n",
    "    parts = [p for p in parts if p]\n",
    "    if not parts:\n",
    "        return col_name\n",
    "\n",
    "    first = parts[0].lower()\n",
    "    rest = [p[:1].upper() + p[1:].lower() for p in parts[1:]]\n",
    "    return first + \"\".join(rest)\n",
    "\n",
    "\n",
    "def rename_columns_to_camel(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with all columns renamed to camelCase.\n",
    "    \"\"\"\n",
    "    for c in df.columns:\n",
    "        new_name = to_camel_case(c)\n",
    "        if new_name != c:\n",
    "            df = df.withColumnRenamed(c, new_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_age_cert(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Standardise ageCertification to a consistent format:\n",
    "    - Uppercase, no spaces\n",
    "    - Replace underscores with dashes\n",
    "    - Map common variants like PG13 -> PG-13\n",
    "    - Fill nulls with 'NR'\n",
    "    \"\"\"\n",
    "    if \"ageCertification\" not in df.columns:\n",
    "        return df\n",
    "\n",
    "    col = F.col(\"ageCertification\")\n",
    "\n",
    "    df = df.withColumn(\"ageCertification\", F.upper(F.trim(col)))\n",
    "    df = df.withColumn(\"ageCertification\", F.regexp_replace(\"ageCertification\", r\"\\s+\", \"\"))\n",
    "    df = df.withColumn(\"ageCertification\", F.regexp_replace(\"ageCertification\", \"_\", \"-\"))\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .withColumn(\n",
    "            \"ageCertification\",\n",
    "            F.when(F.col(\"ageCertification\") == \"PG13\", \"PG-13\")\n",
    "             .when(F.col(\"ageCertification\") == \"TVMA\", \"TV-MA\")\n",
    "             .when(F.col(\"ageCertification\") == \"NC17\", \"NC-17\")\n",
    "             .otherwise(F.col(\"ageCertification\"))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"ageCertification\",\n",
    "            F.when(\n",
    "                F.col(\"ageCertification\").isNull() | (F.col(\"ageCertification\") == \"\"),\n",
    "                F.lit(\"NR\")\n",
    "            ).otherwise(F.col(\"ageCertification\"))\n",
    "        )\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_runtime_to_minutes_col(col: F.Column) -> F.Column:\n",
    "    \"\"\"\n",
    "    Parse runtime strings into integer minutes.\n",
    "    Handles:\n",
    "      '95'       -> 95\n",
    "      '95m'      -> 95\n",
    "      '1h 40m'   -> 100\n",
    "      '2h'       -> 120\n",
    "    \"\"\"\n",
    "    clean = F.trim(col.cast(\"string\"))\n",
    "\n",
    "    return (\n",
    "        F.when(clean.rlike(r\"^[0-9]+$\"),\n",
    "               clean.cast(\"int\"))\n",
    "         .when(clean.rlike(r\"^[0-9]+m$\"),\n",
    "               F.regexp_extract(clean, r\"([0-9]+)\", 1).cast(\"int\"))\n",
    "         .when(clean.rlike(r\"^[0-9]+h\\s*[0-9]+m$\"),\n",
    "               (F.regexp_extract(clean, r\"([0-9]+)h\", 1).cast(\"int\") * F.lit(60) +\n",
    "                F.regexp_extract(clean, r\"h\\s*([0-9]+)m\", 1).cast(\"int\")))\n",
    "         .when(clean.rlike(r\"^[0-9]+h$\"),\n",
    "               F.regexp_extract(clean, r\"([0-9]+)\", 1).cast(\"int\") * F.lit(60))\n",
    "         .otherwise(F.lit(None).cast(\"int\"))\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_votes_to_int_col(col: F.Column) -> F.Column:\n",
    "    \"\"\"\n",
    "    Parse votes strings into integer (BIGINT) counts.\n",
    "    Handles:\n",
    "      '123,456'    -> 123456\n",
    "      '808582.0'   -> 808582\n",
    "      '926K'       -> 926000\n",
    "      '1.2M'       -> 1200000\n",
    "    \"\"\"\n",
    "    raw = F.trim(col.cast(\"string\"))\n",
    "    no_commas = F.regexp_replace(raw, \",\", \"\")\n",
    "\n",
    "    return (\n",
    "        # Simple integer or decimal (e.g. '808582' or '808582.0')\n",
    "        F.when(\n",
    "            no_commas.rlike(r\"^[0-9]+(\\.[0-9]+)?$\"),\n",
    "            no_commas.cast(\"double\").cast(\"bigint\")\n",
    "        )\n",
    "        # Thousands with K/k (e.g. '926K', '1.2K')\n",
    "        .when(\n",
    "            no_commas.rlike(r\"^[0-9]+(\\.[0-9]+)?[Kk]$\"),\n",
    "            (\n",
    "                F.regexp_extract(no_commas, r\"([0-9]+(?:\\.[0-9]+)?)\", 1)\n",
    "                 .cast(\"double\") * F.lit(1000)\n",
    "            ).cast(\"bigint\")\n",
    "        )\n",
    "        # Millions with M/m (e.g. '1.2M')\n",
    "        .when(\n",
    "            no_commas.rlike(r\"^[0-9]+(\\.[0-9]+)?[Mm]$\"),\n",
    "            (\n",
    "                F.regexp_extract(no_commas, r\"([0-9]+(?:\\.[0-9]+)?)\", 1)\n",
    "                 .cast(\"double\") * F.lit(1000000)\n",
    "            ).cast(\"bigint\")\n",
    "        )\n",
    "        .otherwise(F.lit(None).cast(\"bigint\"))\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_valid_title(df: DataFrame, title_col: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Remove junk records where the title is null, empty, or '[]'.\n",
    "    \"\"\"\n",
    "    return df.filter(\n",
    "        F.col(title_col).isNotNull() &\n",
    "        (F.trim(F.col(title_col)) != \"\") &\n",
    "        (F.trim(F.col(title_col)) != \"[]\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8aac12ba-222d-47b4-b4b3-6af9e2771856",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Silver – Netflix Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7183ac89-afbc-46d1-87f8-17ff386e99a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "bronze_titles = spark.table(\"workspace.bronze.netflix_titles_raw\")\n",
    "bronze_credits = spark.table(\"workspace.bronze.netflix_credits_raw\")\n",
    "\n",
    "netflix_titles = rename_columns_to_camel(bronze_titles)\n",
    "netflix_credits = rename_columns_to_camel(bronze_credits)\n",
    "\n",
    "netflix_titles = clean_string_columns(netflix_titles)\n",
    "netflix_credits = clean_string_columns(netflix_credits)\n",
    "\n",
    "# Keep MOVIE type only\n",
    "netflix_titles = netflix_titles.filter(F.upper(F.col(\"type\")) == \"MOVIE\")\n",
    "\n",
    "# Clean title and normalised title\n",
    "netflix_titles = netflix_titles.withColumn(\n",
    "    \"titleClean\",\n",
    "    F.trim(F.regexp_replace(F.col(\"title\"), r\"^\\s*[0-9]+\\.\\s*\", \"\"))\n",
    ")\n",
    "netflix_titles = filter_valid_title(netflix_titles, \"titleClean\")\n",
    "netflix_titles = netflix_titles.withColumn(\"titleNorm\", F.lower(F.col(\"titleClean\")))\n",
    "\n",
    "# Normalise age certificate\n",
    "netflix_titles = normalize_age_cert(netflix_titles)\n",
    "\n",
    "# Cast numeric fields\n",
    "netflix_titles = (\n",
    "    netflix_titles\n",
    "    .withColumn(\"releaseYear\", F.col(\"releaseYear\").cast(\"int\"))\n",
    "    .withColumn(\n",
    "        \"runtimeMinutes\",\n",
    "        F.when(F.col(\"runtime\").rlike(r\"^[0-9]+$\"),\n",
    "               F.col(\"runtime\").cast(\"int\"))\n",
    "         .otherwise(F.lit(None).cast(\"int\"))\n",
    "    )\n",
    "    .withColumn(\"imdbScore\", F.col(\"imdbScore\").cast(\"double\"))\n",
    "    .withColumn(\"imdbVotes\", parse_votes_to_int_col(F.col(\"imdbVotes\")))\n",
    "    .withColumn(\"tmdbPopularity\", F.col(\"tmdbPopularity\").cast(\"double\"))\n",
    "    .withColumn(\"tmdbScore\", F.col(\"tmdbScore\").cast(\"double\"))\n",
    ")\n",
    "\n",
    "# Director from credits: earliest personId for role DIRECTOR\n",
    "netflix_directors = (\n",
    "    netflix_credits\n",
    "    .filter(F.upper(F.col(\"role\")) == \"DIRECTOR\")\n",
    "    .withColumn(\"personId\", F.col(\"personId\").cast(\"bigint\"))\n",
    ")\n",
    "\n",
    "w_dir = Window.partitionBy(\"id\").orderBy(F.col(\"personId\").asc_nulls_last())\n",
    "netflix_directors = (\n",
    "    netflix_directors\n",
    "    .withColumn(\"rn\", F.row_number().over(w_dir))\n",
    "    .filter(F.col(\"rn\") == 1)\n",
    "    .drop(\"rn\")\n",
    "    .select(\n",
    "        \"id\",\n",
    "        \"personId\",\n",
    "        F.col(\"name\").alias(\"director\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Join titles + directors\n",
    "netflix_movies = (\n",
    "    netflix_titles\n",
    "    .join(netflix_directors, on=\"id\", how=\"left\")\n",
    ")\n",
    "\n",
    "# For same title + releaseYear, keep MOVIE with highest imdbScore (then imdbVotes)\n",
    "w_netflix_title_year = (\n",
    "    Window\n",
    "    .partitionBy(\"titleNorm\", \"releaseYear\")\n",
    "    .orderBy(\n",
    "        F.col(\"imdbScore\").desc_nulls_last(),\n",
    "        F.col(\"imdbVotes\").desc_nulls_last()\n",
    "    )\n",
    ")\n",
    "netflix_movies = (\n",
    "    netflix_movies\n",
    "    .withColumn(\"rn_title_year\", F.row_number().over(w_netflix_title_year))\n",
    "    .filter(F.col(\"rn_title_year\") == 1)\n",
    "    .drop(\"rn_title_year\")\n",
    ")\n",
    "\n",
    "# Select final Netflix Silver columns\n",
    "netflix_movies = netflix_movies.select(\n",
    "    F.col(\"id\").alias(\"netflixId\"),\n",
    "    F.col(\"titleClean\").alias(\"title\"),\n",
    "    F.col(\"titleNorm\").alias(\"titleNorm\"),\n",
    "    F.col(\"type\").alias(\"showType\"),\n",
    "    F.col(\"description\").alias(\"description\"),\n",
    "    F.col(\"releaseYear\").alias(\"releaseYear\"),\n",
    "    F.col(\"ageCertification\").alias(\"ageCertification\"),\n",
    "    F.col(\"runtimeMinutes\").alias(\"runtimeMinutes\"),\n",
    "    F.col(\"genres\").alias(\"genres\"),\n",
    "    F.col(\"productionCountries\").alias(\"productionCountries\"),\n",
    "    F.col(\"imdbId\").alias(\"imdbId\"),\n",
    "    F.col(\"imdbScore\").alias(\"imdbScore\"),\n",
    "    F.col(\"imdbVotes\").alias(\"imdbVotes\"),\n",
    "    F.col(\"tmdbPopularity\").alias(\"tmdbPopularity\"),\n",
    "    F.col(\"tmdbScore\").alias(\"tmdbScore\"),\n",
    "    F.col(\"director\").alias(\"director\")\n",
    ")\n",
    "\n",
    "netflix_movies = rename_columns_to_camel(netflix_movies)\n",
    "\n",
    "netflix_movies.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\n",
    "    \"workspace.silver.netflix_movies\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cd04ebc-a1c3-4572-a509-1ce20f6cc295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Silver – IMDB Movies (from merged Bronze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87bed1fa-5c01-4e26-9baf-5de1f070b579",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "imdb_bronze = spark.table(\"workspace.bronze.imdb_merged_movies_raw\")\n",
    "\n",
    "imdb_df = rename_columns_to_camel(imdb_bronze)\n",
    "imdb_df = clean_string_columns(imdb_df)\n",
    "\n",
    "# Cast raw 'year'\n",
    "imdb_df = imdb_df.withColumn(\"year\", F.col(\"year\").cast(\"int\"))\n",
    "\n",
    "# Derive releaseYear from releaseDate when possible, else fall back to 'year'.\n",
    "imdb_df = imdb_df.withColumn(\n",
    "    \"releaseYearFromDate\",\n",
    "    F.expr(\"year(try_to_date(releaseDate, 'MMMM d, yyyy'))\")\n",
    ")\n",
    "imdb_df = imdb_df.withColumn(\n",
    "    \"releaseYear\",\n",
    "    F.when(F.col(\"releaseYearFromDate\").isNotNull(),\n",
    "           F.col(\"releaseYearFromDate\").cast(\"int\"))\n",
    "     .otherwise(F.col(\"year\"))\n",
    ")\n",
    "\n",
    "# Clean title + normalised title\n",
    "imdb_df = imdb_df.withColumn(\n",
    "    \"titleClean\",\n",
    "    F.trim(F.regexp_replace(F.col(\"title\"), r\"^\\s*[0-9]+\\.\\s*\", \"\"))\n",
    ")\n",
    "imdb_df = filter_valid_title(imdb_df, \"titleClean\")\n",
    "imdb_df = imdb_df.withColumn(\"titleNorm\", F.lower(F.col(\"titleClean\")))\n",
    "\n",
    "# Parse runtime from 'duration'\n",
    "if \"duration\" in imdb_df.columns:\n",
    "    imdb_df = imdb_df.withColumn(\n",
    "        \"runtimeMinutes\",\n",
    "        parse_runtime_to_minutes_col(F.col(\"duration\"))\n",
    "    )\n",
    "else:\n",
    "    imdb_df = imdb_df.withColumn(\"runtimeMinutes\", F.lit(None).cast(\"int\"))\n",
    "\n",
    "# IMDB rating numeric (this is the official IMDB rating from IMDB dataset)\n",
    "if \"rating\" in imdb_df.columns:\n",
    "    imdb_df = imdb_df.withColumn(\"imdbRating\", F.col(\"rating\").cast(\"double\"))\n",
    "else:\n",
    "    imdb_df = imdb_df.withColumn(\"imdbRating\", F.lit(None).cast(\"double\"))\n",
    "\n",
    "# IMDB votes as BIGINT (priority dataset for votes)\n",
    "if \"votes\" in imdb_df.columns:\n",
    "    imdb_df = imdb_df.withColumn(\"imdbVotes\", parse_votes_to_int_col(F.col(\"votes\")))\n",
    "else:\n",
    "    imdb_df = imdb_df.withColumn(\"imdbVotes\", F.lit(None).cast(\"bigint\"))\n",
    "\n",
    "# imdbId from movieLink\n",
    "if \"movieLink\" in imdb_df.columns:\n",
    "    imdb_df = imdb_df.withColumn(\n",
    "        \"imdbId\",\n",
    "        F.regexp_extract(F.col(\"movieLink\"), r\"(tt[0-9]+)\", 0)\n",
    "    )\n",
    "else:\n",
    "    imdb_df = imdb_df.withColumn(\"imdbId\", F.lit(None).cast(\"string\"))\n",
    "\n",
    "# Deduplicate IMDB: one row per (titleNorm, releaseYear) with highest rating then votes\n",
    "w_imdb = (\n",
    "    Window.partitionBy(\"titleNorm\", \"releaseYear\")\n",
    "          .orderBy(\n",
    "              F.col(\"imdbRating\").desc_nulls_last(),\n",
    "              F.col(\"imdbVotes\").desc_nulls_last()\n",
    "          )\n",
    ")\n",
    "imdb_df = (\n",
    "    imdb_df\n",
    "    .withColumn(\"rn\", F.row_number().over(w_imdb))\n",
    "    .filter(F.col(\"rn\") == 1)\n",
    "    .drop(\"rn\")\n",
    ")\n",
    "\n",
    "imdb_movies = imdb_df.select(\n",
    "    F.col(\"titleClean\").alias(\"title\"),\n",
    "    F.col(\"titleNorm\").alias(\"titleNorm\"),\n",
    "    F.col(\"releaseYear\").alias(\"releaseYear\"),\n",
    "    F.col(\"runtimeMinutes\").alias(\"runtimeMinutes\"),\n",
    "    F.col(\"imdbRating\").alias(\"imdbRating\"),\n",
    "    F.col(\"imdbVotes\").alias(\"imdbVotes\"),\n",
    "    F.col(\"imdbId\").alias(\"imdbId\"),\n",
    "    F.col(\"fileYear\").alias(\"fileYear\")\n",
    ")\n",
    "\n",
    "imdb_movies = rename_columns_to_camel(imdb_movies)\n",
    "\n",
    "imdb_movies.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .saveAsTable(\"workspace.silver.imdb_movies\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea11488e-68f1-47d0-9e27-a1444d15cbc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Combined Silver movies table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53ba501f-a349-4a4c-89ce-11644ea77e37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "netflix_movies = spark.table(\"workspace.silver.netflix_movies\")\n",
    "imdb_movies = spark.table(\"workspace.silver.imdb_movies\")\n",
    "\n",
    "n = netflix_movies.alias(\"n\")\n",
    "i = imdb_movies.alias(\"i\")\n",
    "\n",
    "# Join:\n",
    "# 1) primary on imdbId (generated imdbid from Link colun)\n",
    "# 2) fallback on (titleNorm, releaseYear) when imdbId is null\n",
    "join_condition = (\n",
    "    (F.col(\"n.imdbId\").isNotNull() & (F.col(\"n.imdbId\") == F.col(\"i.imdbId\"))) |\n",
    "    (F.col(\"n.imdbId\").isNull() &\n",
    "     (F.col(\"n.titleNorm\") == F.col(\"i.titleNorm\")) &\n",
    "     (F.col(\"n.releaseYear\") == F.col(\"i.releaseYear\")))\n",
    ")\n",
    "\n",
    "movies_joined = n.join(i, join_condition, how=\"left\")\n",
    "\n",
    "# --- Final rating & votes ---\n",
    "# Rating: IMDB dataset first; if that doesn't exist, use Netflix imdbScore as fallback\n",
    "movies_joined = (\n",
    "    movies_joined\n",
    "    .withColumn(\n",
    "        \"imdbRatingFinal\",\n",
    "        F.coalesce(F.col(\"i.imdbRating\"), F.col(\"n.imdbScore\").cast(\"double\"))\n",
    "    )\n",
    "    # Votes: IMDB dataset first. if that doesn't exist then fall back to Netflix imdbVotes\n",
    "    .withColumn(\n",
    "        \"imdbVotesFinal\",\n",
    "        F.coalesce(F.col(\"i.imdbVotes\"), F.col(\"n.imdbVotes\").cast(\"bigint\"))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"hasImdbMatch\",\n",
    "        F.when(F.col(\"i.imdbId\").isNotNull(), F.lit(True)).otherwise(F.lit(False))\n",
    "    )\n",
    ")\n",
    "\n",
    "final_movies = movies_joined.select(\n",
    "    F.col(\"n.netflixId\").alias(\"netflixId\"),\n",
    "    F.col(\"n.title\").alias(\"title\"),\n",
    "    F.col(\"n.releaseYear\").alias(\"releaseYear\"),\n",
    "    F.col(\"n.runtimeMinutes\").alias(\"runtimeMinutes\"),\n",
    "    F.col(\"n.ageCertification\").alias(\"ageCertification\"),\n",
    "    F.col(\"n.director\").alias(\"director\"),\n",
    "    F.col(\"n.genres\").alias(\"genres\"),\n",
    "    F.col(\"n.productionCountries\").alias(\"productionCountries\"),\n",
    "    F.col(\"n.showType\").alias(\"showType\"),\n",
    "    F.col(\"n.imdbId\").alias(\"imdbId\"),\n",
    "    F.col(\"imdbRatingFinal\").alias(\"imdbRating\"),\n",
    "    F.col(\"imdbVotesFinal\").alias(\"imdbVotes\"),\n",
    "    F.col(\"n.tmdbPopularity\").alias(\"tmdbPopularity\"),\n",
    "    F.col(\"n.tmdbScore\").alias(\"tmdbScore\"),\n",
    "    F.col(\"hasImdbMatch\").alias(\"hasImdbMatch\")\n",
    ")\n",
    "\n",
    "# Remove any remaining junk titles \n",
    "final_movies = filter_valid_title(final_movies, \"title\")\n",
    "\n",
    "# Columns to camelCase\n",
    "final_movies = rename_columns_to_camel(final_movies)\n",
    "\n",
    "final_movies.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\n",
    "    \"workspace.silver.movies\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6399644130179000,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Silver_Cleansing_And_Conformance",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
